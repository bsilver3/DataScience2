{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bsilver3\\AppData\\Local\\Temp\\ipykernel_23244\\3404073856.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df = df.fillna(df.median())\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"penguins.csv\")\n",
    "\n",
    "df = df.fillna(df.median())\n",
    "\n",
    "# One-hot encode categorical features\n",
    "cat_columns = df.select_dtypes(include=['object']).columns\n",
    "df_encoded = pd.get_dummies(df, columns=cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Body Mass (g)                                1.000000\n",
       "Flipper Length (mm)                          0.871221\n",
       "Species_Gentoo penguin (Pygoscelis papua)    0.815005\n",
       "Island_Biscoe                                0.625432\n",
       "Culmen Length (mm)                           0.594925\n",
       "Sex_MALE                                     0.421879\n",
       "Date Egg_11/27/07                            0.249049\n",
       "Date Egg_11/29/07                            0.182912\n",
       "Date Egg_12/1/09                             0.165891\n",
       "Individual ID_N56A2                          0.165112\n",
       "Date Egg_11/4/08                             0.162482\n",
       "Individual ID_N39A2                          0.162384\n",
       "Date Egg_11/25/09                            0.161142\n",
       "Date Egg_11/22/09                            0.144450\n",
       "Individual ID_N32A2                          0.136934\n",
       "Date Egg_11/3/08                             0.130264\n",
       "Clutch Completion_Yes                        0.127328\n",
       "Individual ID_N36A2                          0.125188\n",
       "Individual ID_N19A2                          0.117229\n",
       "Individual ID_N58A2                          0.105258\n",
       "Individual ID_N20A2                          0.104061\n",
       "Individual ID_N14A2                          0.102864\n",
       "Individual ID_N31A2                          0.101367\n",
       "Date Egg_11/20/09                            0.099964\n",
       "Individual ID_N35A2                          0.099739\n",
       "Individual ID_N15A2                          0.098076\n",
       "Date Egg_11/2/08                             0.091622\n",
       "Individual ID_N18A2                          0.089950\n",
       "Individual ID_N47A2                          0.089697\n",
       "Date Egg_11/9/08                             0.089649\n",
       "Individual ID_N60A2                          0.087302\n",
       "Individual ID_N6A2                           0.084077\n",
       "Individual ID_N8A1                           0.082120\n",
       "Date Egg_12/3/07                             0.081889\n",
       "Individual ID_N46A2                          0.081317\n",
       "Individual ID_N43A2                          0.081082\n",
       "Individual ID_N33A1                          0.081082\n",
       "Individual ID_N34A2                          0.078204\n",
       "Individual ID_N55A2                          0.075332\n",
       "Date Egg_11/18/07                            0.074135\n",
       "Individual ID_N4A2                           0.072938\n",
       "Individual ID_N13A2                          0.070374\n",
       "Date Egg_11/6/08                             0.070225\n",
       "Individual ID_N15A1                          0.069346\n",
       "Individual ID_N43A1                          0.067559\n",
       "Individual ID_N37A2                          0.064558\n",
       "Individual ID_N56A1                          0.064558\n",
       "Individual ID_N8A2                           0.062543\n",
       "Individual ID_N28A2                          0.060585\n",
       "Individual ID_N20A1                          0.058573\n",
       "Name: Body Mass (g), dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.corr()[\"Body Mass (g)\"].nlargest(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root condition:\n",
      "Feature: Species_Gentoo penguin (Pygoscelis papua)\n",
      "Threshold: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Define Node class for decision tree\n",
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None, value=None, left=None, right=None):\n",
    "        self.feature_index = feature_index  # Index of feature to split on\n",
    "        self.threshold = threshold  # Threshold value to split the feature\n",
    "        self.value = value  # Value to return if node is a leaf node\n",
    "        self.left = left  # Left child (less than threshold)\n",
    "        self.right = right  # Right child (greater than or equal to threshold)\n",
    "\n",
    "\n",
    "# Define Decision Tree Regression class\n",
    "class DecisionTreeRegressor:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        n_samples, n_features = X.shape\n",
    "        variance = np.var(y)\n",
    "\n",
    "        if depth == self.max_depth or n_samples == 1 or variance == 0:\n",
    "            return Node(value=np.mean(y))\n",
    "\n",
    "        best_variance_reduction = 0\n",
    "        best_feature_index = None\n",
    "        best_threshold = None\n",
    "\n",
    "        for feature_index in range(n_features):\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = np.where(X[:, feature_index] < threshold)\n",
    "                right_indices = np.where(X[:, feature_index] >= threshold)\n",
    "\n",
    "                left_variance = np.var(y[left_indices])\n",
    "                right_variance = np.var(y[right_indices])\n",
    "\n",
    "                reduction = variance - (left_variance + right_variance)\n",
    "                if reduction > best_variance_reduction:\n",
    "                    best_variance_reduction = reduction\n",
    "                    best_feature_index = feature_index\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        if best_variance_reduction == 0:\n",
    "            return Node(value=np.mean(y))\n",
    "\n",
    "        left_indices = np.where(X[:, best_feature_index] < best_threshold)\n",
    "        right_indices = np.where(X[:, best_feature_index] >= best_threshold)\n",
    "\n",
    "        left_child = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_child = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return Node(feature_index=best_feature_index, threshold=best_threshold, left=left_child, right=right_child)\n",
    "\n",
    "    def print_root_condition(self):\n",
    "        print(\"Root condition:\")\n",
    "        print(f\"Feature: {feature_names[self.root.feature_index]}\")\n",
    "        print(f\"Threshold: {self.root.threshold}\")\n",
    "\n",
    "X = df_encoded.drop(columns=['Body Mass (g)']).values\n",
    "y = df_encoded['Body Mass (g)'].values\n",
    "feature_names = list(df_encoded.drop(columns=['Body Mass (g)']).columns)\n",
    "\n",
    "# Create and fit decision tree regressor\n",
    "tree_regressor = DecisionTreeRegressor(max_depth=3)\n",
    "tree_regressor.fit(X, y)\n",
    "\n",
    "# Visualize the decision tree\n",
    "tree_regressor.print_root_condition()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
