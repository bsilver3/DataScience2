{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cancer.csv')\n",
    "\n",
    "df = df.drop(\"STDs: Time since first diagnosis\", axis=1)\n",
    "df = df.drop(\"STDs: Time since last diagnosis\", axis=1)\n",
    "\n",
    "# Replace \"?\" with actual values\n",
    "df.replace(\"?\", pd.NA, inplace=True)\n",
    "# df.dropna(inplace=True)\n",
    "df = df.fillna(df.median())\n",
    "\n",
    "for column in df.columns:\n",
    "    df[column] = pd.to_numeric(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(inputted_predictions, actual):\n",
    "    correct = sum(inputted_predictions == actual)\n",
    "    total = len(actual)\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Biopsy']\n",
    "\n",
    "# Extract numeric columns\n",
    "numeric_cols = df.select_dtypes(include=['int', 'float']).columns\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()  # Or MinMaxScaler()\n",
    "\n",
    "# Scale the numeric columns\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df.drop('Biopsy', axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.predictions = []\n",
    "        for x_test in X:\n",
    "            distances = np.sqrt(np.sum((self.X_train - x_test) ** 2, axis=1))\n",
    "            nearest_neighbors = np.argsort(distances)[:self.k]\n",
    "            knn_labels = self.y_train[nearest_neighbors].astype(int)\n",
    "            most_common = np.argmax(np.bincount(knn_labels))\n",
    "            if most_common > 0.5:\n",
    "                self.predictions.append(1)\n",
    "            else:\n",
    "                self.predictions.append(most_common)\n",
    "        return self.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Test Accuracy: 0.9418604651162791\n",
      "K-Nearest Neighbors Train Accuracy: 0.9431486880466472\n",
      "K-Nearest Neighbors Test Accuracy (Alternate Method): 0.9418604651162791\n",
      "K-Nearest Neighbors Train Accuracy (Alternate Method): 0.9431486880466472\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the KNN classifier\n",
    "knn = KNN(10)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Calculate test accuracy\n",
    "knn_test_predictions = knn.predict(X_test.values)\n",
    "knn_test_accuracy = accuracy_score(knn_test_predictions, y_test.values)\n",
    "print(\"K-Nearest Neighbors Test Accuracy:\", knn_test_accuracy)\n",
    "\n",
    "# Calculate train accuracy\n",
    "knn_train_predictions = knn.predict(X_train.values)\n",
    "knn_train_accuracy = accuracy_score(knn_train_predictions, y_train.values)\n",
    "print(\"K-Nearest Neighbors Train Accuracy:\", knn_train_accuracy)\n",
    "\n",
    "knn_test_accuracy = calculate_accuracy(knn_test_predictions, y_test.values)\n",
    "print(\"K-Nearest Neighbors Test Accuracy (Alternate Method):\", knn_test_accuracy)\n",
    "knn_train_accuracy = calculate_accuracy(knn_train_predictions, y_train.values)\n",
    "print(\"K-Nearest Neighbors Train Accuracy (Alternate Method):\", knn_train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value  # Value if the node is a leaf node\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        self.n_features = X.shape[1]\n",
    "        self.tree = self._grow_tree(X, y)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        n_samples_per_class = [np.sum(y == i) for i in range(self.n_classes)]\n",
    "        # Stopping criteria\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or np.max(n_samples_per_class) == n_samples:\n",
    "            leaf_value = np.argmax(n_samples_per_class)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        # Find the best split\n",
    "        best_gini = np.inf\n",
    "        best_criteria = None\n",
    "        best_sets = None\n",
    "        for feature_index in range(n_features):\n",
    "            feature_values = np.unique(X[:, feature_index])\n",
    "            for threshold in feature_values:\n",
    "                left_indices = np.where(X[:, feature_index] <= threshold)[0]\n",
    "                right_indices = np.where(X[:, feature_index] > threshold)[0]\n",
    "                gini = self._gini(y[left_indices], y[right_indices])\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_criteria = (feature_index, threshold)\n",
    "                    best_sets = (left_indices, right_indices)\n",
    "\n",
    "        # Create subtrees\n",
    "        left = self._grow_tree(X[best_sets[0]], y[best_sets[0]], depth + 1)\n",
    "        right = self._grow_tree(X[best_sets[1]], y[best_sets[1]], depth + 1)\n",
    "        return Node(feature_index=best_criteria[0], threshold=best_criteria[1], left=left, right=right)\n",
    "\n",
    "    def _gini(self, *groups):\n",
    "        total_samples = sum(len(group) for group in groups)\n",
    "        gini = 0.0\n",
    "        for group in groups:\n",
    "            size = float(len(group))\n",
    "            if size == 0:\n",
    "                continue\n",
    "            score = 0.0\n",
    "            for class_val in range(self.n_classes):\n",
    "                p = [np.sum(group == class_val) / size for group in groups]\n",
    "                score += p[class_val] ** 2\n",
    "            gini += (1.0 - score) * (size / total_samples)\n",
    "        return gini\n",
    "\n",
    "    def _predict(self, x, tree):\n",
    "        if tree.value is not None:\n",
    "            return tree.value\n",
    "        feature_value = x[tree.feature_index]\n",
    "        subtree = tree.right\n",
    "        if feature_value <= tree.threshold:\n",
    "            subtree = tree.left\n",
    "        return self._predict(x, subtree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict(x, self.tree) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the DecisionTree classifier\n",
    "decision_tree = DecisionTree(max_depth=2)\n",
    "\n",
    "# Fit the model to the training data\n",
    "decision_tree.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Test Accuracy: 0.9534883720930233\n",
      "Decision Tree Classification Train Accuracy: 0.9329446064139941\n",
      "Decision Tree Classification Test Accuracy (Alternate Method): 0.9534883720930233\n",
      "Decision Tree Classification Train Accuracy (Alternate Method): 0.9329446064139941\n"
     ]
    }
   ],
   "source": [
    "# Calculate test accuracy\n",
    "dtc_test_predictions = decision_tree.predict(X_test.values)\n",
    "dtc_test_accuracy = accuracy_score(dtc_test_predictions, y_test.values)\n",
    "print(\"Decision Tree Classification Test Accuracy:\", dtc_test_accuracy)\n",
    "\n",
    "# Calculate train accuracy\n",
    "dtc_train_predictions = decision_tree.predict(X_train.values)\n",
    "dtc_train_accuracy = accuracy_score(dtc_train_predictions, y_train.values)\n",
    "print(\"Decision Tree Classification Train Accuracy:\", dtc_train_accuracy)\n",
    "\n",
    "dtc_test_accuracy = calculate_accuracy(dtc_test_predictions, y_test.values)\n",
    "print(\"Decision Tree Classification Test Accuracy (Alternate Method):\", dtc_test_accuracy)\n",
    "dtc_train_accuracy = calculate_accuracy(dtc_train_predictions, y_train.values)\n",
    "print(\"Decision Tree Classification Train Accuracy (Alternate Method):\", dtc_train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_probabilities = {}\n",
    "        self.feature_parameters = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.class_probabilities = dict(y.value_counts(normalize=True))\n",
    "\n",
    "        for label in self.class_probabilities:\n",
    "            label_data = X[y == label]\n",
    "            self.feature_parameters[label] = {}\n",
    "            for feature in X.columns:\n",
    "                mean = label_data[feature].mean()\n",
    "                std = label_data[feature].std()\n",
    "                self.feature_parameters[label][feature] = (mean, std)\n",
    "\n",
    "    def _calculate_probability(self, x, mean, std):\n",
    "        exponent = np.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
    "        return (1 / (np.sqrt(2 * np.pi) * std)) * exponent\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for _, row in X.iterrows():\n",
    "            probabilities = {}\n",
    "            for label in self.class_probabilities:\n",
    "                probabilities[label] = self.class_probabilities[label]\n",
    "                for feature in self.feature_parameters[label]:\n",
    "                    mean, std = self.feature_parameters[label][feature]\n",
    "                    probabilities[label] *= self._calculate_probability(row[feature], mean, std)\n",
    "            predictions.append(max(probabilities, key=probabilities.get))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bsilver3\\AppData\\Local\\Temp\\ipykernel_20508\\777883403.py:18: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  exponent = np.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
      "C:\\Users\\bsilver3\\AppData\\Local\\Temp\\ipykernel_20508\\777883403.py:19: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return (1 / (np.sqrt(2 * np.pi) * std)) * exponent\n",
      "C:\\Users\\bsilver3\\AppData\\Local\\Temp\\ipykernel_20508\\777883403.py:18: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  exponent = np.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
      "C:\\Users\\bsilver3\\AppData\\Local\\Temp\\ipykernel_20508\\777883403.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (1 / (np.sqrt(2 * np.pi) * std)) * exponent\n",
      "C:\\Users\\bsilver3\\AppData\\Local\\Temp\\ipykernel_20508\\777883403.py:18: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  exponent = np.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
      "C:\\Users\\bsilver3\\AppData\\Local\\Temp\\ipykernel_20508\\777883403.py:19: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return (1 / (np.sqrt(2 * np.pi) * std)) * exponent\n",
      "C:\\Users\\bsilver3\\AppData\\Local\\Temp\\ipykernel_20508\\777883403.py:18: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  exponent = np.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
      "C:\\Users\\bsilver3\\AppData\\Local\\Temp\\ipykernel_20508\\777883403.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (1 / (np.sqrt(2 * np.pi) * std)) * exponent\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and train the classifier\n",
    "classifier = GaussianNaiveBayesClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Calculate test accuracy\n",
    "gnb_test_predictions = classifier.predict(X_test)\n",
    "gnb_test_accuracy = accuracy_score(gnb_test_predictions, y_test.values)\n",
    "\n",
    "# Calculate train accuracy\n",
    "gnb_train_predictions = classifier.predict(X_train)\n",
    "gnb_train_accuracy = accuracy_score(gnb_train_predictions, y_train.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Test Accuracy: 0.9534883720930233\n",
      "Gaussian Naive Bayes Train Accuracy: 0.9314868804664723\n",
      "Gaussian Naive Bayes Test Accuracy (Alternate Method): 0.9534883720930233\n",
      "Gaussian Naive Bayes Train Accuracy (Alternate Method): 0.9314868804664723\n"
     ]
    }
   ],
   "source": [
    "print(\"Gaussian Naive Bayes Test Accuracy:\", gnb_test_accuracy)\n",
    "print(\"Gaussian Naive Bayes Train Accuracy:\", gnb_train_accuracy)\n",
    "\n",
    "gnb_test_accuracy = calculate_accuracy(gnb_test_predictions, y_test.values)\n",
    "gnb_train_accuracy = calculate_accuracy(gnb_train_predictions, y_train.values)\n",
    "print(\"Gaussian Naive Bayes Test Accuracy (Alternate Method):\", gnb_test_accuracy)\n",
    "print(\"Gaussian Naive Bayes Train Accuracy (Alternate Method):\", gnb_train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Test Accuracy: 0.9476744186046512\n",
      "K-Nearest Neighbors Train Accuracy: 0.9460641399416909\n",
      "Decision Tree Classification Test Accuracy: 0.9534883720930233\n",
      "Decision Tree Classification Train Accuracy: 0.9329446064139941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bsilver3\\AppData\\Local\\Temp\\ipykernel_20508\\777883403.py:18: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  exponent = np.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
      "C:\\Users\\bsilver3\\AppData\\Local\\Temp\\ipykernel_20508\\777883403.py:19: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return (1 / (np.sqrt(2 * np.pi) * std)) * exponent\n",
      "C:\\Users\\bsilver3\\AppData\\Local\\Temp\\ipykernel_20508\\777883403.py:18: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  exponent = np.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
      "C:\\Users\\bsilver3\\AppData\\Local\\Temp\\ipykernel_20508\\777883403.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (1 / (np.sqrt(2 * np.pi) * std)) * exponent\n",
      "C:\\Users\\bsilver3\\AppData\\Local\\Temp\\ipykernel_20508\\777883403.py:18: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  exponent = np.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
      "C:\\Users\\bsilver3\\AppData\\Local\\Temp\\ipykernel_20508\\777883403.py:19: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return (1 / (np.sqrt(2 * np.pi) * std)) * exponent\n",
      "C:\\Users\\bsilver3\\AppData\\Local\\Temp\\ipykernel_20508\\777883403.py:18: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  exponent = np.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
      "C:\\Users\\bsilver3\\AppData\\Local\\Temp\\ipykernel_20508\\777883403.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (1 / (np.sqrt(2 * np.pi) * std)) * exponent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Test Accuracy: 0.9534883720930233\n",
      "Gaussian Naive Bayes Train Accuracy: 0.9314868804664723\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors:\n",
    "knn_test_predictions = knn.predict(X_test.values)\n",
    "knn_test_accuracy = accuracy_score(knn_test_predictions, y_test.values)\n",
    "print(\"K-Nearest Neighbors Test Accuracy:\", knn_test_accuracy)\n",
    "\n",
    "# Calculate train accuracy\n",
    "knn_train_predictions = knn.predict(X_train.values)\n",
    "knn_train_accuracy = accuracy_score(knn_train_predictions, y_train.values)\n",
    "print(\"K-Nearest Neighbors Train Accuracy:\", knn_train_accuracy)\n",
    "\n",
    "# knn_test_accuracy = calculate_accuracy(knn_test_predictions, y_test.values)\n",
    "# print(\"K-Nearest Neighbors Test Accuracy (Alternate Method):\", knn_test_accuracy)\n",
    "# knn_train_accuracy = calculate_accuracy(knn_train_predictions, y_train.values)\n",
    "# print(\"K-Nearest Neighbors Train Accuracy (Alternate Method):\", knn_train_accuracy)\n",
    "\n",
    "\n",
    "# Decision Tree Classification:\n",
    "# Calculate test accuracy\n",
    "dtc_test_predictions = decision_tree.predict(X_test.values)\n",
    "dtc_test_accuracy = accuracy_score(dtc_test_predictions, y_test.values)\n",
    "print(\"Decision Tree Classification Test Accuracy:\", dtc_test_accuracy)\n",
    "\n",
    "# Calculate train accuracy\n",
    "dtc_train_predictions = decision_tree.predict(X_train.values)\n",
    "dtc_train_accuracy = accuracy_score(dtc_train_predictions, y_train.values)\n",
    "print(\"Decision Tree Classification Train Accuracy:\", dtc_train_accuracy)\n",
    "\n",
    "# dtc_test_accuracy = calculate_accuracy(dtc_test_predictions, y_test.values)\n",
    "# print(\"Decision Tree Classification Test Accuracy (Alternate Method):\", dtc_test_accuracy)\n",
    "# dtc_train_accuracy = calculate_accuracy(dtc_train_predictions, y_train.values)\n",
    "# print(\"Decision Tree Classification Train Accuracy (Alternate Method):\", dtc_train_accuracy)\n",
    "\n",
    "\n",
    "# Gaussian Naive Bayes:\n",
    "# Calculate test accuracy\n",
    "gnb_test_predictions = classifier.predict(X_test)\n",
    "gnb_test_accuracy = accuracy_score(gnb_test_predictions, y_test.values)\n",
    "\n",
    "# Calculate train accuracy\n",
    "gnb_train_predictions = classifier.predict(X_train)\n",
    "gnb_train_accuracy = accuracy_score(gnb_train_predictions, y_train.values)\n",
    "print(\"Gaussian Naive Bayes Test Accuracy:\", gnb_test_accuracy)\n",
    "print(\"Gaussian Naive Bayes Train Accuracy:\", gnb_train_accuracy)\n",
    "\n",
    "# gnb_test_accuracy = calculate_accuracy(gnb_test_predictions, y_test.values)\n",
    "# gnb_train_accuracy = calculate_accuracy(gnb_train_predictions, y_train.values)\n",
    "# print(\"Gaussian Naive Bayes Test Accuracy (Alternate Method):\", gnb_test_accuracy)\n",
    "# print(\"Gaussian Naive Bayes Train Accuracy (Alternate Method):\", gnb_train_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
